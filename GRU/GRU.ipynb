{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3dba6f3-e769-4cc9-99f2-d4c477438a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d06848-17ce-4106-9561-9cfe3bc3e7c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11be3cc6-cbbd-4ca3-af62-190aa2e2332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9999f9c7-519b-418c-a583-0bda407e7ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "795146b7-22b7-4476-8419-79cc8031a72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df['Lyric'])\n",
    "sequences = tokenizer.texts_to_sequences(df['Lyric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6577ab11-b776-418c-be68-71a88d4aeda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sequences = pad_sequences(sequences, maxlen=100, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edb46521-4243-49bd-9535-ace3add0c602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df['Label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "00b48af3-0920-4c24-91cf-2443a75a90bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Method1\n",
    "# Define GRU model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=5000, output_dim=32, input_length=100),\n",
    "    tf.keras.layers.GRU(units=32),\n",
    "    tf.keras.layers.Dense(units=1, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4cd12783-d4db-4500-bdb6-b0c3711678ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e2d879e0-a0cf-467a-a297-f7eb6589d00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3959/3959 [==============================] - 215s 53ms/step - loss: 0.0000e+00 - accuracy: 3.3154e-04 - val_loss: 0.0000e+00 - val_accuracy: 4.7362e-04\n",
      "Epoch 2/5\n",
      "3959/3959 [==============================] - 205s 52ms/step - loss: 0.0000e+00 - accuracy: 3.3154e-04 - val_loss: 0.0000e+00 - val_accuracy: 4.7362e-04\n",
      "Epoch 3/5\n",
      "3959/3959 [==============================] - 207s 52ms/step - loss: 0.0000e+00 - accuracy: 3.3154e-04 - val_loss: 0.0000e+00 - val_accuracy: 4.7362e-04\n",
      "Epoch 4/5\n",
      "3959/3959 [==============================] - 208s 52ms/step - loss: 0.0000e+00 - accuracy: 3.3154e-04 - val_loss: 0.0000e+00 - val_accuracy: 4.7362e-04\n",
      "Epoch 5/5\n",
      "3959/3959 [==============================] - 213s 54ms/step - loss: 0.0000e+00 - accuracy: 3.3154e-04 - val_loss: 0.0000e+00 - val_accuracy: 4.7362e-04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(X_train, y_train, epochs=5,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "464b1170-29db-4c33-850a-45e0293df8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  26,    4,    3,   82,   28,    3,   83,  360,    5,   14,  122,\n",
       "         20,   18,  284,    1,    3,   54,  177,  951,    6,   41,   10,\n",
       "        116,   33,  229,   72,    3,   54,  177,  951,   58, 1856,   30,\n",
       "          4,   74,  714,  564,  564,  714,    1,    2,  420,   45,  841,\n",
       "         12,   45, 2728,    3,   45,  618,   11,   12,    6,    8, 3391,\n",
       "          5,    3,  294,    3,   83,   41,   77,  331,  100,  244,   77,\n",
       "         81,    9,    2,  244,   21,  277,    6,  495,    1,  857,  857,\n",
       "        857,  857,  857,  857, 4113,  857,  857,  857,  857,  857,  857,\n",
       "       4113,  857,  857,  857,  857,  857,  857, 4113,  857,  857, 4113,\n",
       "          1])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c5ffb91e-6fda-45bf-bc59-cc9460672149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990/990 [==============================] - 22s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53653098-0715-45bc-85e2-fd7fceb6a32c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f942f00f-dc6e-4059-a6db-dee69b9bd306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cef5ddbf-6b73-488d-b2bc-c10bda49aae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, GRU, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f5e93927-9719-4edf-8dd9-f27b601e3c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e18a1917-f68c-4f05-a29b-2725c030599a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "lyrics = df['Lyric']\n",
    "y_train = df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32c935f7-84f3-4d83-9bbf-52d5bac52fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df['Lyric'])\n",
    "sequences = tokenizer.texts_to_sequences(df['Lyric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abf47d47-a853-4ba0-b7ef-f8df16e3c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(sequences, maxlen=100, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5535c631-a9e0-4767-8a1c-cc5072e9e91f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33efc606-f7aa-4849-99fa-8caee0f6b025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10af6f79-155c-4bd8-9c29-9f3a745ffd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=100\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10000, output_dim=128, input_length=max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c79c20e-9997-4462-b720-9bc942aa30aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add one GRU layer, one fully connected layer and one dropout layer\n",
    "model.add(GRU(units=32))\n",
    "model.add(Dense(units=10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165b5187-84a8-4b41-871a-8c475e19c5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab71479-d765-48e7-9c25-60b8b2242e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5feb18c-252e-4378-8f79-1894372e7bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15/63 [======>.......................] - ETA: 4s - loss: 2.2629 - accuracy: 0.3083"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\zyt\\AppData\\Local\\Temp\\ipykernel_13612\\3891671918.py\", line 3, in <module>\n      model.fit(x_train, y_train, epochs=10, batch_size=32)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n      return self.compiled_loss(\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\losses.py\", line 272, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\losses.py\", line 2084, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\backend.py\", line 5630, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nReceived a label value of 10 which is outside the valid range of [0, 10).  Label values: 4 5 6 5 8 4 6 5 5 10 5 5 5 5 6 5 6 6 5 5 6 5 5 5 6 6 6 6 6 5 5 5\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_15866]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Model compile and fit\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mE:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\zyt\\AppData\\Local\\Temp\\ipykernel_13612\\3891671918.py\", line 3, in <module>\n      model.fit(x_train, y_train, epochs=10, batch_size=32)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n      return self.compiled_loss(\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\losses.py\", line 272, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\losses.py\", line 2084, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\backend.py\", line 5630, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nReceived a label value of 10 which is outside the valid range of [0, 10).  Label values: 4 5 6 5 8 4 6 5 5 10 5 5 5 5 6 5 6 6 5 5 6 5 5 5 6 6 6 6 6 5 5 5\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_15866]"
     ]
    }
   ],
   "source": [
    "#Model compile and fit\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f03617-125c-4d4f-9a2b-2d3371a21b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2fdb45-cc00-4a94-826b-efc6d4bfa820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6a0b2cb-9cb2-4af0-b850-4d52bf01d8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d934045-a8ef-41e6-8f5d-f2d808b6ef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = [\"I'm feeling happy and joyful\", \"I'm so sad and lonely\", \"This song makes me feel excited\"]\n",
    "labels = [1, 0, 1]  # 1 represents positive sentiment, 0 represents negative sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "434cd3ee-316c-471a-9404-781119634b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "lyrics = df['Lyric']\n",
    "labels = df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ba060b-56c9-46c5-a07c-12fcb6dfe60e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e8d2c1a-1d6d-4c65-bfea-5b9168264dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lyrics)\n",
    "sequences = tokenizer.texts_to_sequences(lyrics)\n",
    "padded_sequences = pad_sequences(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d51c6df7-92a9-4a78-b88f-4bb0ba28516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "padded_sequences = np.array(padded_sequences)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e5917f5-62b7-4d65-9b1b-51bde4b66148",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(tokenizer.word_index) + 1, 16))  # Embedding层将词索引映射到固定大小的向量\n",
    "model.add(GRU(32))  # GRU层\n",
    "model.add(Dense(10, activation='softmax'))  # 全连接层，输出二进制分类结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd89bc99-23fe-426d-8aaf-a25503faf387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_7\" is incompatible with the layer: expected shape=(None, 100), found shape=(None, 1062)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadded_sequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file2o3iw876.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"E:\\Software\\Anaconda\\envs\\760GRU\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_7\" is incompatible with the layer: expected shape=(None, 100), found shape=(None, 1062)\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(padded_sequences, labels, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab228a7c-d175-48e9-8d2e-b73b125a8fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a866835-28c1-4960-822b-b30a54efbb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 769ms/step - loss: 0.6588 - accuracy: 0.6667\n",
      "Model accuracy: 66.67%\n"
     ]
    }
   ],
   "source": [
    "# 评估模型性能\n",
    "loss, accuracy = model.evaluate(padded_sequences, labels)\n",
    "print(f'Model accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17723f96-ddad-4ba5-b0d9-f6ce185a0207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测新歌词的情感\n",
    "new_lyrics = [\"I'm feeling blue and down\", \"This song is uplifting\"]\n",
    "new_sequences = tokenizer.texts_to_sequences(new_lyrics)\n",
    "new_padded_sequences = pad_sequences(new_sequences, maxlen=padded_sequences.shape[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2279ffbd-3cda-413e-9153-c0d06c88370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测新歌词的情感\n",
    "df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "829cb6f6-d399-4e45-9ea9-1662eaebd91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 608ms/step\n",
      "[1, 1]\n"
     ]
    }
   ],
   "source": [
    "# 对新歌词进行情感预测\n",
    "predictions = model.predict(new_padded_sequences)\n",
    "predicted_labels = [1 if prediction > 0.5 else 0 for prediction in predictions]\n",
    "\n",
    "print(predicted_labels)  # 输出预测的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4ef815-0462-4551-870e-e077e82b9b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2ded55-93a2-4169-94d1-1257bb384297",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e22c72a5-ea1b-4931-91ae-5c5163e88b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, GRU, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4615e348-9957-41e0-bb78-2170127d6dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lyrics and labels\n",
    "df = pd.read_csv('train.csv')\n",
    "lyrics = df['Lyric']\n",
    "labels = df['Label']\n",
    "\n",
    "\n",
    "# parameter setting\n",
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "max_length = 100\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e8022df1-9f14-43b7-946b-67f64aca715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tokenizer\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(lyrics)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# sequence and fill\n",
    "sequences = tokenizer.texts_to_sequences(lyrics)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "labels = np.array(labels)-1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ad2f416-bcd8-49b9-ac33-dca43a5a0b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Construct the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
    "model.add(GRU(32))\n",
    "model.add(Dense(10, activation='softmax')) # Because our emotional labels are 1-10, the last layer uses 10 neurons\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])   #loss function\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a07a177b-139d-4220-84d9-d0a8e5f552f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "63/63 [==============================] - 7s 63ms/step - loss: 1.8686 - accuracy: 0.3735\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 4s 66ms/step - loss: 1.4516 - accuracy: 0.3665\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 4s 59ms/step - loss: 1.3941 - accuracy: 0.4000\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 4s 60ms/step - loss: 1.3403 - accuracy: 0.4175\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 4s 61ms/step - loss: 1.2442 - accuracy: 0.4335\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 4s 59ms/step - loss: 1.1315 - accuracy: 0.5420\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 1.0095 - accuracy: 0.6160\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 4s 59ms/step - loss: 0.8860 - accuracy: 0.6770\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 4s 57ms/step - loss: 0.7689 - accuracy: 0.7215\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 4s 58ms/step - loss: 0.6958 - accuracy: 0.7480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x218dec9b730>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model fit\n",
    "model.fit(padded_sequences, labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ee77988-e4a8-49cd-be36-cceb3466503b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 3s 40ms/step - loss: 0.6272 - accuracy: 0.8010\n",
      "Model accuracy: 80.10%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance\n",
    "loss, accuracy = model.evaluate(padded_sequences, labels)\n",
    "print(f'Model accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "184ca943-e69a-4987-9ff5-b73cdd488ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('test.csv')\n",
    "df2['Lyric'] = df2['Lyric'].fillna('')  # \n",
    "new_lyrics = df2['Lyric']\n",
    "new_labels = df2['Label']\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer2 = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer2.fit_on_texts(new_lyrics)\n",
    "\n",
    "# sequence and fill\n",
    "sequences = tokenizer2.texts_to_sequences(new_lyrics)\n",
    "new_padded_sequences = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "93737336-5cce-4eda-8296-2ae761c7c2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 28ms/step\n",
      "Accuracy:  0.3013972055888224\n"
     ]
    }
   ],
   "source": [
    "# predict the test\n",
    "y_pred = model.predict(new_padded_sequences)\n",
    "\n",
    "# Take the label with the highest probability as the prediction result\n",
    "y_pred = np.argmax(y_pred, axis=1) + 1\n",
    "\n",
    "# Accuracy\n",
    "accuracy = np.sum(y_pred == new_labels) / len(new_labels)\n",
    "print('Accuracy: ', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307b93c3-5a5f-4431-ad3d-2d31a8364b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc083c3-03c6-4b88-b9d6-80594e792597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
