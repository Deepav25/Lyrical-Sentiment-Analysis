{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b14e6fb-a396-4e07-b06c-72fed8de0889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, GRU, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "903856c5-325f-4b18-9b93-69ffb3d5c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lyrics and labels\n",
    "df = pd.read_csv('train.csv')\n",
    "lyrics = df['Lyric']\n",
    "labels = df['Label']\n",
    "val_df = pd.read_csv('validate.csv')\n",
    "val_lyrics = df['Lyric']\n",
    "val_labels = df['Label']\n",
    "\n",
    "# parameter setting\n",
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "max_length = 100\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "592baaf7-c3cd-440f-acdd-e01b1f1c3add",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "# Tokenizer\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(lyrics)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# sequence and fill\n",
    "sequences = tokenizer.texts_to_sequences(lyrics)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "labels = np.array(labels)-1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac3e8287-2240-4ce2-a74a-a7c8d45fdc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validate\n",
    "# Tokenizer\n",
    "val_tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "val_tokenizer.fit_on_texts(val_lyrics)\n",
    "\n",
    "# sequence and fill\n",
    "val_sequences = val_tokenizer.texts_to_sequences(val_lyrics)\n",
    "val_padded_sequences = pad_sequences(val_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "val_labels = np.array(val_labels)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1633fa8a-c6f4-48f1-9584-b92a99e685c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
    "model.add(GRU(64))\n",
    "model.add(Dense(10, activation='softmax')) # Because our emotional labels are 1-10, the last layer uses 10 neurons\n",
    "\n",
    "# Build an optimizer to set the LR\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])   #loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33ad9c4d-7cae-4c96-831a-a95790a21ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "63/63 [==============================] - 11s 133ms/step - loss: 1.7389 - accuracy: 0.3635 - val_loss: 1.4164 - val_accuracy: 0.3825\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 8s 123ms/step - loss: 1.4082 - accuracy: 0.3860 - val_loss: 1.3911 - val_accuracy: 0.3975\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 7s 108ms/step - loss: 1.3788 - accuracy: 0.4355 - val_loss: 1.3423 - val_accuracy: 0.3995\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 7s 107ms/step - loss: 1.3097 - accuracy: 0.4790 - val_loss: 1.2140 - val_accuracy: 0.5255\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 7s 104ms/step - loss: 1.2040 - accuracy: 0.5300 - val_loss: 1.0882 - val_accuracy: 0.5765\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 7s 108ms/step - loss: 1.0395 - accuracy: 0.5885 - val_loss: 0.8835 - val_accuracy: 0.6640\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 7s 112ms/step - loss: 0.8718 - accuracy: 0.6705 - val_loss: 0.7265 - val_accuracy: 0.7325\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 7s 105ms/step - loss: 0.7435 - accuracy: 0.7235 - val_loss: 0.5885 - val_accuracy: 0.7775\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 7s 112ms/step - loss: 0.6116 - accuracy: 0.7800 - val_loss: 0.5203 - val_accuracy: 0.8125\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 7s 112ms/step - loss: 0.5044 - accuracy: 0.8260 - val_loss: 0.4073 - val_accuracy: 0.8710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23261128310>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model fit\n",
    "model.fit(padded_sequences, labels, epochs=10,validation_data=(val_padded_sequences, val_labels),batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07f2893c-8cdf-46ac-973e-6b0d99b99317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 3s 40ms/step - loss: 0.4073 - accuracy: 0.8710\n",
      "Model accuracy: 87.10%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance\n",
    "loss, accuracy = model.evaluate(padded_sequences, labels)\n",
    "print(f'Model accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83e89a16-c3e3-493f-8e05-f371e837894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('test.csv')\n",
    "df2['Lyric'] = df2['Lyric'].fillna('')  # \n",
    "new_lyrics = df2['Lyric']\n",
    "new_labels = df2['Label']\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer2 = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer2.fit_on_texts(new_lyrics)\n",
    "\n",
    "# sequence and fill\n",
    "sequences = tokenizer2.texts_to_sequences(new_lyrics)\n",
    "new_padded_sequences = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d68702eb-5f6f-4266-96e8-9e11cc67ec6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 52ms/step\n",
      "Accuracy:  0.3013972055888224\n"
     ]
    }
   ],
   "source": [
    "# predict the test\n",
    "y_pred = model.predict(new_padded_sequences)\n",
    "\n",
    "# Take the label with the highest probability as the prediction result\n",
    "y_pred = np.argmax(y_pred, axis=1) + 1\n",
    "\n",
    "# Accuracy\n",
    "accuracy = np.sum(y_pred == new_labels) / len(new_labels)\n",
    "print('Accuracy: ', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840fb9c0-407c-43f2-b69a-f538e26a165a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
