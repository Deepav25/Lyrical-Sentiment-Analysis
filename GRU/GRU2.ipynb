{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b14e6fb-a396-4e07-b06c-72fed8de0889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, GRU, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "903856c5-325f-4b18-9b93-69ffb3d5c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lyrics and labels\n",
    "df = pd.read_csv('train.csv')\n",
    "lyrics = df['Lyric']\n",
    "labels = df['Label']\n",
    "val_df = pd.read_csv('validate.csv')\n",
    "val_lyrics = df['Lyric']\n",
    "val_labels = df['Label']\n",
    "\n",
    "# parameter setting\n",
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "max_length = 100\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "592baaf7-c3cd-440f-acdd-e01b1f1c3add",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "# Tokenizer\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(lyrics)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# sequence and fill\n",
    "sequences = tokenizer.texts_to_sequences(lyrics)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "labels = np.array(labels)-1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac3e8287-2240-4ce2-a74a-a7c8d45fdc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validate\n",
    "# Tokenizer\n",
    "val_tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "val_tokenizer.fit_on_texts(val_lyrics)\n",
    "\n",
    "# sequence and fill\n",
    "val_sequences = val_tokenizer.texts_to_sequences(val_lyrics)\n",
    "val_padded_sequences = pad_sequences(val_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "val_labels = np.array(val_labels)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1633fa8a-c6f4-48f1-9584-b92a99e685c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
    "model.add(GRU(64))\n",
    "model.add(Dense(10, activation='softmax')) # Because our emotional labels are 1-10, the last layer uses 10 neurons\n",
    "\n",
    "# Build an optimizer to set the LR\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])   #loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f92658-0e39-4dd7-81b6-b0af5e9faf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fit\n",
    "model.fit(padded_sequences, labels, epochs=100,validation_data=(val_padded_sequences, val_labels),batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317404fc-8f3f-43b6-a5cb-f553546b8d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance\n",
    "loss, accuracy = model.evaluate(padded_sequences, labels)\n",
    "print(f'Model accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83e89a16-c3e3-493f-8e05-f371e837894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('test.csv')\n",
    "df2['Lyric'] = df2['Lyric'].fillna('')  # \n",
    "new_lyrics = df2['Lyric']\n",
    "new_labels = df2['Label']\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer2 = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer2.fit_on_texts(new_lyrics)\n",
    "\n",
    "# sequence and fill\n",
    "sequences = tokenizer2.texts_to_sequences(new_lyrics)\n",
    "new_padded_sequences = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840fb9c0-407c-43f2-b69a-f538e26a165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the test\n",
    "y_pred = model.predict(new_padded_sequences)\n",
    "\n",
    "# Take the label with the highest probability as the prediction result\n",
    "y_pred = np.argmax(y_pred, axis=1) + 1\n",
    "\n",
    "# Accuracy\n",
    "accuracy = np.sum(y_pred == new_labels) / len(new_labels)\n",
    "print('Accuracy: ', accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
